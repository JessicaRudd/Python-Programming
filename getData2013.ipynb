{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Import the json library\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.core.display import clear_output\n",
    "\n",
    "from warnings import warn\n",
    "from time import time\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "\n",
    "#https://srome.github.io/Parsing-HTML-Tables-in-Python-with-BeautifulSoup-and-pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"https://games.crossfit.com/scores/leaderboard.php?stage=5&sort=0&division=1&region=0&regional=5&numberperpage=60&userid=0&competition=0&frontpage=0&expanded=1&year=13&full=1&showtoggles=0&hidedropdowns=1&showathleteac=1&athletename=&scaled=0\"\n",
    "#start = base + \"open/2016/leaderboards\"\n",
    "parameters = {\"page\":0,\"division\":1,\"region\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region = 0 is worldwide\n",
    "divisionList = [1,2] #TODO: get division from table not hardcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Jessica Rudd, jrudd1@students.kennesaw.edu',\n",
    "    'From': 'jrudd1@students.kennesaw.edu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "yearList = []\n",
    "competitionTypeList = []\n",
    "\n",
    "affilliateNameList= []\n",
    "ageList = []\n",
    "competitorIdList = []\n",
    "competitorNameList = []\n",
    "genderList = []\n",
    "heightList = []\n",
    "professionList = []\n",
    "\n",
    "divisionIdList = []\n",
    "professionList = []\n",
    "regionIdList = []\n",
    "regionNameList = [] ###\n",
    "teamCaptainList = []\n",
    "weightList = []\n",
    "\n",
    "scoreOverallList= []\n",
    "scoreOverallRank= []\n",
    "\n",
    "scoreOneList = []\n",
    "scoreTwoList = []\n",
    "scoreThreeList = []\n",
    "scoreFourList = []\n",
    "scoreFiveList = []\n",
    "scoreSixList = []\n",
    "\n",
    "scoreOneDisplayList = []\n",
    "scoreTwoDisplayList = []\n",
    "scoreThreeDisplayList = []\n",
    "scoreFourDisplayList = []\n",
    "scoreFiveDisplayList = []\n",
    "scoreSixDisplayList = []\n",
    "\n",
    "scoreOneRankList = []\n",
    "scoreTwoRankList = []\n",
    "scoreThreeRankList = []\n",
    "scoreFourRankList = []\n",
    "scoreFiveRankList = []\n",
    "scoreSixRankList = []\n",
    "\n",
    "errorList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "requestcount = 0\n",
    "totalcount = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with help from https://srome.github.io/Parsing-HTML-Tables-in-Python-with-BeautifulSoup-and-pandas/\n",
    "\n",
    "class HTMLTableParser:\n",
    "\n",
    "    def parse_url(self, url, parameters):\n",
    "        response = requests.get(url,headers=headers,params=parameters)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        return [(table['id'],self.parse_html_table(table))\\\n",
    "                for table in soup.find_all('table')]  \n",
    "\n",
    "    def parse_html_table(self, table):\n",
    "        n_columns = 0\n",
    "        n_rows=0\n",
    "        column_names = []\n",
    "\n",
    "        # Find number of rows and columns\n",
    "        # we also find the column titles if we can\n",
    "        for row in table.find_all('tr'):\n",
    "\n",
    "            # Determine the number of rows in the table\n",
    "            td_tags = row.find_all('td')\n",
    "            if len(td_tags) > 0:\n",
    "                n_rows+=1\n",
    "                if n_columns == 0:\n",
    "                    # Set the number of columns for our table\n",
    "                    n_columns = len(td_tags)\n",
    "\n",
    "            # Handle column names if we find them\n",
    "            th_tags = row.find_all('th') \n",
    "            if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                for th in th_tags:\n",
    "                    column_names.append(th.get_text())\n",
    "\n",
    "        # Safeguard on Column Titles\n",
    "        if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "            column_names.append(\"\") #TODO: this temp fix\n",
    "            #raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "        columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "        df = pd.DataFrame(columns = columns,\n",
    "                          index= range(0,n_rows))\n",
    "        #print(df.head())\n",
    "        row_marker = 0\n",
    "        for row in table.find_all('tr'):\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                df.iat[row_marker,column_marker] = column.get_text()\n",
    "                column_marker += 1\n",
    "            if len(columns) > 0:\n",
    "                row_marker += 1\n",
    "        #print(df.head())\n",
    "        # Convert to float if possible\n",
    "        for col in df:\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            \n",
    "        # this added to clean\n",
    "        #TODO: fix this correctly\n",
    "       # df.drop(df.columns[0:7],axis=1,inplace=True)\n",
    "        df.columns = column_names\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need how to parse \\n1 (143)\\n Validated by: V... into rank 1 score 143\n",
    "#need to iterate through list using values\n",
    "#create function returning two lists and assign as tuples\n",
    "def parseCrossString(myString):\n",
    "    return myString.split(\"\\n\",1)[1].split(\" \",1)[0],re.sub('[()]', '', myString.split(\"\\n\",1)[1].split(\" \",1)[1].split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request:1 of 1 for Division 11 and Region Africa; Errors: 0 Frequency: 0.9255798578055769 requests/s for 1 total requests\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Request:1 of 1 for Division 11 and Region Asia; Errors: 0 Frequency: 0.5289725811789205 requests/s for 2 total requests\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Request:1 of 3 for Division 11 and Region Australia; Errors: 0 Frequency: 0.3246253515262052 requests/s for 3 total requests\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Request:1 of 2 for Division 11 and Region Canada East; Errors: 0 Frequency: 0.2336368832982012 requests/s for 4 total requests\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Request:1 of 1 for Division 11 and Region Canada West; Errors: 0 Frequency: 0.1956835176811551 requests/s for 5 total requests\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#for each region need to iterate through and get page count\n",
    "for division in divisionList:\n",
    "    \n",
    "    # need to get regions to iterate through\n",
    "    region = {}\n",
    "    parameters = {\"page\":0,\"division\":division}\n",
    "    response = requests.get(start,headers = headers)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    mydivs = soup.findAll('div', {'class': 'form-item form-type-select form-item-division '})\n",
    "    for div in mydivs:\n",
    "        if div.label.text == 'Region ':\n",
    "            for children in div.findAll('option'):\n",
    "                if children.text.strip() != 'Worldwide':\n",
    "                    region[children['value']] =children.text.strip()\n",
    "\n",
    "    #need number of pages per region\n",
    "    for regionkey, regionvalue in region.items():\n",
    "        \n",
    "        requestcount =0\n",
    "        \n",
    "        #need way to get max page number eg 237 will be by region\n",
    "        parameters = {\"page\":0,\"division\":division,\"region\":regionkey}\n",
    "        response = requests.get(start, params=parameters, headers = headers)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "        mybuttons = soup.findAll('a', {'class': 'button'})\n",
    "        if len(mybuttons) > 0:\n",
    "            numPages = int(mybuttons[0].text)\n",
    "        else:\n",
    "            numPages = 1\n",
    "    \n",
    "        #iterate through each page passing in params\n",
    "        for page in range(1,2):\n",
    "            \n",
    "            try:\n",
    "                parameters = {\"page\":page,\"division\":division,\"region\":regionkey}\n",
    "                \n",
    "                            # Monitor the requests\n",
    "                requestcount += 1\n",
    "                totalcount += 1\n",
    "                elapsed_time = time() - start_time\n",
    "                print('Request:{} of {} for Division {} and Region {}; Errors: {} Frequency: {} requests/s for {} total requests'.format(requestcount, numPages, division, regionvalue, len(errorList),requestcount/elapsed_time, totalcount))\n",
    "                clear_output(wait = True)\n",
    "            \n",
    "                hp = HTMLTableParser()\n",
    "                table = hp.parse_url(start,parameters)[0][1]\n",
    "\n",
    "                #append to competitor list\n",
    "                competitorNameList.append(table['Competitor'].values)\n",
    "\n",
    "                #need to iterate through workout columns and add to lists\n",
    "                for counter,i in enumerate(table[[col for col in table.columns if 'Workout' in col]].columns):\n",
    "                    ranklist,scorelist = map(list,zip(*[parseCrossString(value) for value in table[i]]))\n",
    "                    print(counter)\n",
    "                    if counter==0:\n",
    "                        scoreOneList.append(scorelist)\n",
    "                        scoreOneRankList.append(ranklist)\n",
    "                    if counter==1:\n",
    "                        scoreTwoList.append(scorelist)\n",
    "                        scoreTwoRankList.append(ranklist)\n",
    "                    if counter==2:\n",
    "                        scoreThreeList.append(scorelist)\n",
    "                        scoreThreeRankList.append(ranklist)\n",
    "                    if counter==3:\n",
    "                        scoreFourList.append(scorelist)\n",
    "                        scoreFourRankList.append(ranklist)\n",
    "                    if counter==4:\n",
    "                        scoreFiveList.append(scorelist)\n",
    "                        scoreFiveRankList.append(ranklist)\n",
    "                    if counter==5:\n",
    "                        scoreSixList.append(scorelist)\n",
    "                        scoreSixRankList.append(ranklist)\n",
    "\n",
    "                records = len(table['Competitor'])\n",
    "                yearList.append(['2013'] * records) #TODO: hardcoded because not in this version of API\n",
    "                competitionTypeList.append(['open'] * records) #TODO: hardcoded because not in this version of API\n",
    "\n",
    "                divisionIdList.append([division] * records)\n",
    "                regionIdList.append([regionkey] * records)\n",
    "                regionNameList.append([regionvalue] * records)\n",
    "\n",
    "                # Pause the loop\n",
    "                sleep(randint(8,15)/100)\n",
    "                \n",
    "            except:\n",
    "                errorList.append([parameters]+[response.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.DataFrame({'yearList':[y for x in yearList for y in x],\n",
    "                'competitionType':[y for x in competitionTypeList for y in x],\n",
    "                'regionId':[y for x in regionIdList for y in x],\n",
    "                'regionName':[y for x in regionNameList for y in x],\n",
    "                'divisionId':[y for x in divisionIdList for y in x],\n",
    "                'competitorName':[y for x in competitorNameList for y in x],\n",
    "                \n",
    "                'scoreOne':[y for x in scoreOneList for y in x],\n",
    "                'scoreTwo':[y for x in scoreTwoList for y in x],\n",
    "                'scoreThree':[y for x in scoreThreeList for y in x],\n",
    "                'scoreFour':[y for x in scoreFourList for y in x],\n",
    "                'scoreFive':[y for x in scoreFiveList for y in x],\n",
    "\n",
    "                'scoreOneRank':[y for x in scoreOneRankList for y in x],\n",
    "                'scoreTwoRank':[y for x in scoreTwoRankList for y in x],\n",
    "                'scoreThreeRank':[y for x in scoreThreeRankList for y in x],\n",
    "                'scoreFourRank':[y for x in scoreFourRankList for y in x],\n",
    "                'scoreFiveRank':[y for x in scoreFiveRankList for y in x]\n",
    "             }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scoreThreeList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a29fc8a432eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscoreThreeList\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scoreThreeList' is not defined"
     ]
    }
   ],
   "source": [
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.to_csv('data2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
